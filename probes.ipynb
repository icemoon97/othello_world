{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make deterministic\n",
    "from mingpt.utils import set_seed\n",
    "set_seed(44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from data.othello import Othello, OthelloBoardState, permit_reverse\n",
    "from mingpt.dataset import CharDataset\n",
    "from mingpt.utils import sample\n",
    "from mingpt.model import GPT, GPTConfig, GPTforProbing\n",
    "from mingpt.trainer import Trainer, TrainerConfig\n",
    "from mingpt.probe_model import BatteryProbeClassification, BatteryProbeClassificationTwoLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading probes\n",
    "exp = \"state_tl256_e40\"\n",
    "probes = {}\n",
    "for layer in range(1, 9):\n",
    "    p = BatteryProbeClassificationTwoLayer(torch.cuda.current_device(), probe_class=3, num_task=64, mid_dim=256)\n",
    "    load_res = p.load_state_dict(torch.load(f\"./ckpts/grok/probes/{exp}/layer{layer}/checkpoint.ckpt\"))\n",
    "    p.eval()\n",
    "    probes[layer] = p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "othello = Othello(n_games=100, deduplicate=False)\n",
    "train_dataset = CharDataset(othello)\n",
    "\n",
    "mconf = GPTConfig(61, 59, n_layer=8, n_head=8, n_embd=512)\n",
    "model = GPTforProbing(mconf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.731401647594826, 17.801225762873486, 16.90723339160839, 17.143346710108077, 17.491358073744433, 18.251698585505405, 19.345117477219752, 21.353305785123965\n"
     ]
    }
   ],
   "source": [
    "# summarizing probe loss\n",
    "\n",
    "import json\n",
    "\n",
    "root = f\"ckpts/bias/probes/state_tl256_b95\"\n",
    "errs = []\n",
    "for i in range(8):\n",
    "    name = f\"layer{i+1}/tensorboard.txt\"\n",
    "    with open(f\"{root}/{name}\", \"r\") as file:\n",
    "        j = json.load(file)\n",
    "        test_acc = j['test_acc_cont']\n",
    "        err = 100 * (1 - test_acc[-1])\n",
    "        errs.append(err)\n",
    "        # print(f\"layer {i+1} error rate: {err:.5f}\")\n",
    "\n",
    "print(\", \".join([str(e) for e in errs]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "othello",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
