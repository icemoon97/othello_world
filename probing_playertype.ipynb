{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make deterministic\n",
    "from mingpt.utils import set_seed\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from data.othello import Othello, OthelloBoardState\n",
    "from mingpt.dataset import CharDataset\n",
    "from mingpt.model import GPT, GPTConfig, GPTforProbing\n",
    "from mingpt.probe_trainer import Trainer, TrainerConfig\n",
    "from mingpt.probe_model import BatteryProbeClassification, BatteryProbeClassificationTwoLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ckpt = \"playertype/playertype_e40\"\n",
    "probe_root = \"playertype\"\n",
    "probe_type = \"player\" # player or state\n",
    "probe_layer = 8\n",
    "twolayer = False\n",
    "epo = 16\n",
    "mid_dim = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mem Used: 8.717 GB:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment for playertype/probes/player\n",
      "Loaded 100000 from 1 files\n",
      "Using 10000 for training, 0 for validation\n",
      "Dataset created has 10000 sequences, 61 unique words.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "folder_name = f\"{probe_root}/probes/{probe_type}\"\n",
    "\n",
    "if twolayer:\n",
    "    folder_name = folder_name + f\"_tl{mid_dim}\"  # tl for probes without batchnorm\n",
    "\n",
    "print(f\"Running experiment for {folder_name}\")\n",
    "othello = Othello(data_root=\"othello_1player\", n_games=10000, deduplicate=False, test_split=0)\n",
    "\n",
    "player_types, games = zip(*othello)\n",
    "train_dataset = CharDataset(games)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "mconf = GPTConfig(train_dataset.vocab_size, train_dataset.block_size, n_layer=8, n_head=8, n_embd=512)\n",
    "model = GPTforProbing(mconf, probe_layer=probe_layer)\n",
    "# if args.random:\n",
    "#     model.apply(model._init_weights)\n",
    "if model_ckpt:  # trained on synthetic dataset\n",
    "    load_res = model.load_state_dict(torch.load(f\"./ckpts/{model_ckpt}.ckpt\"))\n",
    "else:\n",
    "    raise Exception(\"not given ckpt path or random flag\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.cuda.current_device()\n",
    "    model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [01:15<00:00, 132.26it/s]\n"
     ]
    }
   ],
   "source": [
    "# creating dataset of activations and properties\n",
    "loader = DataLoader(train_dataset, shuffle=False, pin_memory=True, batch_size=1, num_workers=1)\n",
    "act_container = []\n",
    "property_container = []\n",
    "\n",
    "for i, (x, y) in tqdm(enumerate(loader), total=len(loader)):\n",
    "    tbf = [train_dataset.itos[_] for _ in x.tolist()[0]]\n",
    "    # truncates game if it is less than 60 moves\n",
    "    valid_until = tbf.index(-100) if -100 in tbf else 999\n",
    "    # gets activations for each move\n",
    "    a = OthelloBoardState()\n",
    "    act = model(x.to(device))[0, ...].detach().cpu()  # [block_size, f]\n",
    "    act_container.extend([_[0] for _ in act.split(1, dim=0)[:valid_until]])\n",
    "\n",
    "    if probe_type == \"state\":\n",
    "        properties = a.get_gt(tbf[:valid_until], \"get_state\")  # [block_size, ]\n",
    "    elif probe_type == \"player\":\n",
    "        properties = [[player_types[i]] for _ in range(len(tbf[:valid_until]))]\n",
    "    property_container.extend(properties)\n",
    "\n",
    "    assert len(act_container) == len(property_container)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 for board state (empty/black/white), 4 for player type (corners)\n",
    "probe_class = 4 \n",
    "# 64 for board state, 1 for player type\n",
    "num_task = 1 \n",
    "\n",
    "if twolayer:\n",
    "    probe = BatteryProbeClassificationTwoLayer(device, probe_class=probe_class, num_task=num_task, mid_dim=mid_dim)\n",
    "else:\n",
    "    probe = BatteryProbeClassification(device, probe_class=probe_class, num_task=num_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "585823 pairs loaded...\n",
      "y: (array([0, 1, 2, 3]), array([150654, 143013, 146761, 145395]))\n"
     ]
    }
   ],
   "source": [
    "class ProbingDataset(Dataset):\n",
    "    def __init__(self, act, y):\n",
    "        assert len(act) == len(y)\n",
    "        print(f\"{len(act)} pairs loaded...\")\n",
    "        self.act = act\n",
    "        self.y = y\n",
    "        # print(np.sum(np.array(y)==0), np.sum(np.array(y)==1), np.sum(np.array(y)==2))\n",
    "        print(\"y:\", np.unique(y, return_counts=True))\n",
    "        \n",
    "    def __len__(self, ):\n",
    "        return len(self.y)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.act[idx], torch.tensor(self.y[idx]).to(torch.long)\n",
    "\n",
    "probing_dataset = ProbingDataset(act_container, property_container)\n",
    "train_size = int(0.8 * len(probing_dataset))\n",
    "test_size = len(probing_dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(probing_dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = epo\n",
    "t_start = time.strftime(\"_%Y%m%d_%H%M%S\")\n",
    "tconf = TrainerConfig(\n",
    "    max_epochs=max_epochs, \n",
    "    batch_size=1024, \n",
    "    learning_rate=1e-3,\n",
    "    betas=(.9, .999), \n",
    "    lr_decay=True, \n",
    "    warmup_tokens=len(train_dataset)*5, \n",
    "    final_tokens=len(train_dataset)*max_epochs,\n",
    "    num_workers=0, \n",
    "    weight_decay=0., \n",
    "    ckpt_path=os.path.join(\"./ckpts/\", folder_name, f\"layer{probe_layer}\")\n",
    ")\n",
    "trainer = Trainer(probe, train_dataset, test_dataset, tconf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1: train loss 1.57106; lr 1.00e-03; train acc 53.32%:   1%|▏         | 6/458 [00:00<00:08, 54.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decayed: {'proj.weight', 'proj.bias'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1: train loss 1.49397; lr 1.00e-03; train acc 59.38%:   1%|▏         | 6/458 [00:00<00:08, 54.33it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1: train loss 0.11802; lr 1.00e-03; train acc 98.12%: 100%|██████████| 458/458 [00:06<00:00, 75.38it/s]\n",
      "epoch 2: train loss 0.07059; lr 1.00e-03; train acc 97.83%: 100%|██████████| 458/458 [00:05<00:00, 85.56it/s]\n",
      "epoch 3: train loss 0.06960; lr 1.00e-03; train acc 98.12%: 100%|██████████| 458/458 [00:05<00:00, 85.19it/s]\n",
      "epoch 4: train loss 0.06870; lr 1.00e-03; train acc 98.26%: 100%|██████████| 458/458 [00:06<00:00, 75.90it/s]\n",
      "epoch 5: train loss 0.06871; lr 1.00e-03; train acc 97.97%: 100%|██████████| 458/458 [00:05<00:00, 89.13it/s]\n",
      "epoch 6: train loss 0.06641; lr 7.50e-04; train acc 97.97%: 100%|██████████| 458/458 [00:05<00:00, 87.27it/s]\n",
      "epoch 7: train loss 0.06606; lr 7.50e-04; train acc 98.41%: 100%|██████████| 458/458 [00:05<00:00, 77.89it/s]\n",
      "epoch 8: train loss 0.06506; lr 5.63e-04; train acc 97.83%: 100%|██████████| 458/458 [00:05<00:00, 86.92it/s]\n",
      "epoch 9: train loss 0.06352; lr 4.22e-04; train acc 98.26%: 100%|██████████| 458/458 [00:05<00:00, 87.98it/s]\n",
      "epoch 10: train loss 0.06254; lr 3.16e-04; train acc 98.99%: 100%|██████████| 458/458 [00:05<00:00, 86.12it/s]\n",
      "epoch 11: train loss 0.06248; lr 3.16e-04; train acc 96.96%: 100%|██████████| 458/458 [00:06<00:00, 75.84it/s]\n",
      "epoch 12: train loss 0.06235; lr 3.16e-04; train acc 98.70%: 100%|██████████| 458/458 [00:05<00:00, 83.63it/s]\n",
      "epoch 13: train loss 0.06188; lr 2.37e-04; train acc 97.68%: 100%|██████████| 458/458 [00:05<00:00, 84.64it/s]\n",
      "epoch 14: train loss 0.06138; lr 1.78e-04; train acc 97.97%: 100%|██████████| 458/458 [00:05<00:00, 83.25it/s]\n",
      "epoch 15: train loss 0.06124; lr 1.78e-04; train acc 97.68%: 100%|██████████| 458/458 [00:06<00:00, 76.12it/s]\n",
      "epoch 16: train loss 0.06098; lr 1.33e-04; train acc 97.39%: 100%|██████████| 458/458 [00:05<00:00, 84.16it/s]\n"
     ]
    }
   ],
   "source": [
    "trainer.train(prt=True)\n",
    "trainer.save_traces()\n",
    "trainer.save_checkpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trying to debug probes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "probe = BatteryProbeClassification(device, probe_class=4, num_task=1)\n",
    "load_res = probe.load_state_dict(torch.load(f\"./ckpts/playertype/probes/player/layer6/checkpoint.ckpt\"))\n",
    "\n",
    "probe = probe.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3662/3662 [00:07<00:00, 488.84it/s]\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(train_dataset, shuffle=False, pin_memory=True, batch_size=128, num_workers=1)\n",
    "\n",
    "total_states = 0\n",
    "total_correct = 0\n",
    "\n",
    "pbar = tqdm(enumerate(train_loader), total=len(train_loader))\n",
    "for it, (x, y) in pbar:\n",
    "    x = x.to(device)  # [B, f]\n",
    "    y = y.to(device)  # [B, #task=1] \n",
    "\n",
    "    logits, loss = probe(x, y)\n",
    "    pred = torch.argmax(logits, dim=2)\n",
    "    pred = pred.detach().cpu().numpy()\n",
    "\n",
    "    true = y.detach().cpu().numpy()\n",
    "    correct = pred == true\n",
    "    total_correct += np.count_nonzero(correct)\n",
    "\n",
    "    total_states += x.shape[0]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "446590 468658\n",
      "0.9529123582655156\n"
     ]
    }
   ],
   "source": [
    "print(total_correct, total_states)\n",
    "print(total_correct / total_states)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "othello",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
