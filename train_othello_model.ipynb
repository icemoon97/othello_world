{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make deterministic\n",
    "from mingpt.utils import set_seed\n",
    "set_seed(44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from data.othello import Othello, OthelloBoardState, permit_reverse\n",
    "from mingpt.dataset import CharDataset\n",
    "from mingpt.utils import sample\n",
    "from mingpt.model import GPT, GPTConfig\n",
    "from mingpt.trainer import Trainer, TrainerConfig"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mem Used: 4.155 GB: 100%|██████████| 50/50 [00:18<00:00,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5000000 from 50 files\n",
      "Deduplicating finished with 5000000 games left\n",
      "Using 4000000 for training, 1000000 for validation\n",
      "Dataset created has 4000000 sequences, 61 unique words.\n"
     ]
    }
   ],
   "source": [
    "# n_games=-1 means use as many simulated games as possible (from \"data/othello_synthetic/\")\n",
    "othello = Othello(n_games=-1, data_root=\"othello_synthetic\")\n",
    "train_dataset = CharDataset(othello)\n",
    "# original OthelloGPT params: n_layer=8, n_head=8, n_embd=512\n",
    "mconf = GPTConfig(train_dataset.vocab_size, train_dataset.block_size, n_layer=8, n_head=8, n_embd=512)\n",
    "model = GPT(mconf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_res = model.load_state_dict(torch.load(f\"./ckpts/bias/TLbias80.ckpt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.cuda.current_device()\n",
    "    model = model.to(device)\n",
    "else:\n",
    "    print(\"NO GPU FOUND\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_20230710_200458\n"
     ]
    }
   ],
   "source": [
    "# setting up training\n",
    "max_epochs = 5\n",
    "experiment_name = \"ft_bias80\"\n",
    "t_start = time.strftime(\"_%Y%m%d_%H%M%S\")\n",
    "ckpt_path = f\"./ckpts/{experiment_name}_{t_start}.ckpt\"\n",
    "tconf = TrainerConfig(\n",
    "    max_epochs=max_epochs, \n",
    "    batch_size=512*4, # using 4 gpus\n",
    "    learning_rate=1e-4,\n",
    "    lr_decay=False,\n",
    "    # learning_rate=5e-4,\n",
    "    # lr_decay=True, \n",
    "    warmup_tokens=len(train_dataset)*train_dataset.block_size*5, \n",
    "    final_tokens=len(train_dataset)*train_dataset.block_size*max_epochs,\n",
    "    num_workers=0, \n",
    "    ckpt_path=ckpt_path, \n",
    "    save_each_epoch=True,\n",
    ")\n",
    "trainer = Trainer(model, train_dataset, None, tconf)\n",
    "device = trainer.device\n",
    "print(t_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1954 [00:00<?, ?it/s]/net/scratch/jnbaldwin/miniconda3/envs/othello/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "epoch 1 iter 1953: train loss 2.09702. lr 1.000000e-04: 100%|██████████| 1954/1954 [11:40<00:00,  2.79it/s]\n",
      "epoch 2 iter 1953: train loss 2.08321. lr 1.000000e-04: 100%|██████████| 1954/1954 [11:39<00:00,  2.79it/s]\n",
      "epoch 3 iter 1953: train loss 2.06221. lr 1.000000e-04: 100%|██████████| 1954/1954 [11:31<00:00,  2.83it/s]\n",
      "epoch 4 iter 1953: train loss 2.05505. lr 1.000000e-04: 100%|██████████| 1954/1954 [11:32<00:00,  2.82it/s]\n",
      "epoch 5 iter 1953: train loss 2.05773. lr 1.000000e-04: 100%|██████████| 1954/1954 [11:32<00:00,  2.82it/s]\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_othello_model(ckpt):\n",
    "    # original OthelloGPT params: n_layer=8, n_head=8, n_embd=512\n",
    "    # vocab_size = 59, block_size = 61 for othello\n",
    "    mconf = GPTConfig(61, 59, n_layer=8, n_head=8, n_embd=512)\n",
    "    model = GPT(mconf)\n",
    "    load_res = model.load_state_dict(torch.load(f\"./ckpts/{ckpt}.ckpt\"))\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.cuda.current_device()\n",
    "        model = model.to(device)\n",
    "        return model, device\n",
    "    else:\n",
    "        print(\"NO GPU FOUND\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checks if model prediction is legal for each node in given game\n",
    "# expects dataset has already been loaded and model is on GPU\n",
    "def check_legal(model, device, train_dataset, game):\n",
    "    total_nodes = 0\n",
    "    success_nodes = 0\n",
    "\n",
    "    len_whole_game = len(game)\n",
    "    for len_partial_game in range(1, len_whole_game):\n",
    "        total_nodes += 1\n",
    "        context = game[:len_partial_game]\n",
    "        x = torch.tensor([train_dataset.stoi[s] for s in context], dtype=torch.long)[None, ...].to(device)\n",
    "        y = sample(model, x, 1, temperature=1.0)\n",
    "        # taking top-1 prediction\n",
    "        completion = [train_dataset.itos[int(i)] for i in y[0] if i != -1]\n",
    "        try:\n",
    "            OthelloBoardState().update(completion)\n",
    "        except Exception:\n",
    "            # print(completion)\n",
    "            pass\n",
    "        else:\n",
    "            success_nodes += 1\n",
    "    \n",
    "    return total_nodes, success_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default data root is othello_synthetic\n",
    "def validate_with_dataset(model, device, data_root=None, n_games=1000):\n",
    "    # find to load in first n games, because the first ~1 million othello_synthetic games are test set for unbiased model\n",
    "    val_games = Othello(data_root=data_root, n_games=n_games, test_split=1, deduplicate=False)\n",
    "    char = CharDataset(val_games.val)\n",
    "\n",
    "    total_nodes = 0\n",
    "    success_nodes = 0\n",
    "\n",
    "    def progress_report():\n",
    "        return f\"{success_nodes/total_nodes*100:.4f}% pass rate: {success_nodes}/{total_nodes} among all searched nodes\"\n",
    "    \n",
    "    bar = tqdm(val_games.val[:n_games])\n",
    "    for game in bar:\n",
    "        tn, sn = check_legal(model, device, char, game)\n",
    "        total_nodes += tn\n",
    "        success_nodes += sn\n",
    "        bar.set_description(progress_report())\n",
    "    print(progress_report())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_from_checkpoint(ckpt, data_root=None, n_games=1000):\n",
    "    model, device = load_othello_model(ckpt)\n",
    "    validate_with_dataset(model, device, data_root=data_root, n_games=n_games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mem Used: 4.062 GB:   0%|          | 0/50 [00:00<?, ?it/s]\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 100000 from 1 files\n",
      "Using 0 for training, 1000 for validation\n",
      "Dataset created has 1000 sequences, 61 unique words.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "99.9474% pass rate: 58909/58940 among all searched nodes: 100%|██████████| 1000/1000 [06:48<00:00,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.9474% pass rate: 58909/58940 among all searched nodes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "validate_from_checkpoint(\"bias/finetune_bias80_e5\", data_root=\"othello_synthetic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in [\"bias/TLcontrol\", \"bias/TLbias50\", \"bias/TLbias80\", \"bias/TLbias95\"]:\n",
    "    for dr in [\"synthetic\", \"TLbias50\", \"TLbias80\", \"TLbias95\"]:\n",
    "        print(f\"======== ckpt: {c} | data: {dr} =========\")\n",
    "        validate_from_checkpoint(c, data_root=f\"othello_{dr}\", n_games=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eight directions\n",
    "eights = [[-1, 0], [-1, 1], [0, 1], [1, 1], [1, 0], [1, -1], [0, -1], [-1, -1]]\n",
    "def check_adj(ob):\n",
    "    total = 0\n",
    "    occupied = ob.get_occupied()\n",
    "    for i in range(64):\n",
    "        r, c = i // 8, i % 8\n",
    "        adj = False\n",
    "        if occupied[i]:\n",
    "            continue\n",
    "        for dir in eights:\n",
    "            test_r, test_c = r + dir[0], c + dir[1]\n",
    "            if test_r not in range(8) or test_c not in range(8):\n",
    "                continue\n",
    "            if occupied[test_r * 8 + test_c]:\n",
    "                adj = True\n",
    "                break\n",
    "        total += 1 if adj else 0\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mem Used: 1.117 GB:   0%|          | 0/18 [00:00<?, ?it/s]\n",
      "1912/21600, 0.0885:   0%|          | 3/1000 [00:00<00:38, 26.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 100000 from 1 files\n",
      "Using 1000 for training, 0 for validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "333621/3573780, 0.0934: 100%|██████████| 1000/1000 [00:38<00:00, 25.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09335241676879942\n",
      "0.18268010324937659\n",
      "0.41459877417719254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "othello = Othello(data_root=\"othello_TLbias95\", n_games=1000, test_split=0, deduplicate=False)\n",
    "baselines = [\n",
    "    0, # full random\n",
    "    0, # no-repeats random\n",
    "    0  # only adjacent\n",
    "]\n",
    "legal = 0\n",
    "bar = tqdm(othello)\n",
    "for seq in bar:\n",
    "    ob = OthelloBoardState()\n",
    "    for i, move in enumerate(seq):\n",
    "        baselines[0] += 60\n",
    "        baselines[1] += 60 - i\n",
    "        baselines[2] += check_adj(ob)        \n",
    "        legal += len(ob.get_valid_moves())\n",
    "        ob.update([move])\n",
    "    bar.set_description(desc=f\"{legal}/{baselines[0]}, {legal/baselines[0]:.4f}\")\n",
    "\n",
    "for b in baselines:\n",
    "    print(legal/b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "othello",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
