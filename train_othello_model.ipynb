{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make deterministic\n",
    "from mingpt.utils import set_seed\n",
    "set_seed(44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from data.othello import Othello, OthelloBoardState, permit_reverse\n",
    "from mingpt.dataset import CharDataset\n",
    "from mingpt.utils import sample\n",
    "from mingpt.model import GPT, GPTConfig\n",
    "from mingpt.trainer import Trainer, TrainerConfig"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_games=-1 means use as many simulated games as possible (from \"data/othello_synthetic/\")\n",
    "othello = Othello(n_games=1000, data_root=\"othello_topleftbias80\")\n",
    "train_dataset = CharDataset(othello)\n",
    "# original OthelloGPT params: n_layer=8, n_head=8, n_embd=512\n",
    "mconf = GPTConfig(train_dataset.vocab_size, train_dataset.block_size, n_layer=8, n_head=8, n_embd=512)\n",
    "model = GPT(mconf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.cuda.current_device()\n",
    "    model = model.to(device)\n",
    "else:\n",
    "    print(\"NO GPU FOUND\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_20230704_210935\n"
     ]
    }
   ],
   "source": [
    "# setting up training\n",
    "max_epochs = 40\n",
    "experiment_name = \"unbiased_e40\"\n",
    "t_start = time.strftime(\"_%Y%m%d_%H%M%S\")\n",
    "ckpt_path = f\"./ckpts/{experiment_name}_{t_start}.ckpt\"\n",
    "tconf = TrainerConfig(\n",
    "    max_epochs=max_epochs, \n",
    "    batch_size=512*4, # using 4 gpus\n",
    "    learning_rate=5e-4,\n",
    "    lr_decay=True, \n",
    "    warmup_tokens=len(train_dataset)*train_dataset.block_size*5, \n",
    "    final_tokens=len(train_dataset)*train_dataset.block_size*max_epochs,\n",
    "    num_workers=0, \n",
    "    ckpt_path=ckpt_path, \n",
    "    # saved_epochs=[0, 1, 2, 3, 5, 10, 15, 20],\n",
    ")\n",
    "trainer = Trainer(model, train_dataset, None, tconf)\n",
    "device = trainer.device\n",
    "print(t_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_othello_model(ckpt):\n",
    "    # original OthelloGPT params: n_layer=8, n_head=8, n_embd=512\n",
    "    # vocab_size = 59, block_size = 61 for othello\n",
    "    mconf = GPTConfig(61, 59, n_layer=8, n_head=8, n_embd=512)\n",
    "    model = GPT(mconf)\n",
    "    load_res = model.load_state_dict(torch.load(f\"./ckpts/{ckpt}.ckpt\"))\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.cuda.current_device()\n",
    "        model = model.to(device)\n",
    "        return model, device\n",
    "    else:\n",
    "        print(\"NO GPU FOUND\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checks if model prediction is legal for each node in given game\n",
    "# expects dataset has already been loaded and model is on GPU\n",
    "def check_legal(model, device, train_dataset, game):\n",
    "    total_nodes = 0\n",
    "    success_nodes = 0\n",
    "\n",
    "    len_whole_game = len(game)\n",
    "    for len_partial_game in range(1, len_whole_game):\n",
    "        total_nodes += 1\n",
    "        context = game[:len_partial_game]\n",
    "        x = torch.tensor([train_dataset.stoi[s] for s in context], dtype=torch.long)[None, ...].to(device)\n",
    "        y = sample(model, x, 1, temperature=1.0)\n",
    "        # taking top-1 prediction\n",
    "        completion = [train_dataset.itos[int(i)] for i in y[0] if i != -1]\n",
    "        try:\n",
    "            OthelloBoardState().update(completion)\n",
    "        except Exception:\n",
    "            # print(completion)\n",
    "            pass\n",
    "        else:\n",
    "            success_nodes += 1\n",
    "    \n",
    "    return total_nodes, success_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default data root is othello_synthetic\n",
    "def validate_with_dataset(model, device, data_root=None, n_games=1000):\n",
    "    # find to load in first n games, because the first ~1 million othello_synthetic games are test set for unbiased model\n",
    "    val_games = Othello(data_root=data_root, n_games=n_games, test_split=1, deduplicate=False)\n",
    "    char = CharDataset(val_games.val)\n",
    "\n",
    "    total_nodes = 0\n",
    "    success_nodes = 0\n",
    "\n",
    "    def progress_report():\n",
    "        return f\"{success_nodes/total_nodes*100:.4f}% pass rate: {success_nodes}/{total_nodes} among all searched nodes\"\n",
    "    \n",
    "    bar = tqdm(val_games.val[:n_games])\n",
    "    for game in bar:\n",
    "        tn, sn = check_legal(model, device, char, game)\n",
    "        total_nodes += tn\n",
    "        success_nodes += sn\n",
    "        bar.set_description(progress_report())\n",
    "    print(progress_report())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_from_checkpoint(ckpt, data_root=None, n_games=1000):\n",
    "    model, device = load_othello_model(ckpt)\n",
    "    validate_with_dataset(model, device, data_root=data_root, n_games=n_games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_from_checkpoint(\"bias/TLcontrol\", data_root=\"othello_topleftbias80\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in [\"bias/TLcontrol\", \"bias/TLbias50\", \"bias/TLbias80\", \"bias/TLbias95\"]:\n",
    "    for dr in [\"synthetic\", \"TLbias50\", \"TLbias80\", \"TLbias95\"]:\n",
    "        print(f\"======== ckpt: {c} | data: {dr} =========\")\n",
    "        validate_from_checkpoint(c, data_root=f\"othello_{dr}\", n_games=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eight directions\n",
    "eights = [[-1, 0], [-1, 1], [0, 1], [1, 1], [1, 0], [1, -1], [0, -1], [-1, -1]]\n",
    "def check_adj(ob):\n",
    "    total = 0\n",
    "    occupied = ob.get_occupied()\n",
    "    for i in range(64):\n",
    "        r, c = i // 8, i % 8\n",
    "        adj = False\n",
    "        if occupied[i]:\n",
    "            continue\n",
    "        for dir in eights:\n",
    "            test_r, test_c = r + dir[0], c + dir[1]\n",
    "            if test_r not in range(8) or test_c not in range(8):\n",
    "                continue\n",
    "            if occupied[test_r * 8 + test_c]:\n",
    "                adj = True\n",
    "                break\n",
    "        total += 1 if adj else 0\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mem Used: 1.117 GB:   0%|          | 0/18 [00:00<?, ?it/s]\n",
      "1912/21600, 0.0885:   0%|          | 3/1000 [00:00<00:38, 26.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 100000 from 1 files\n",
      "Using 1000 for training, 0 for validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "333621/3573780, 0.0934: 100%|██████████| 1000/1000 [00:38<00:00, 25.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09335241676879942\n",
      "0.18268010324937659\n",
      "0.41459877417719254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "othello = Othello(data_root=\"othello_TLbias95\", n_games=1000, test_split=0, deduplicate=False)\n",
    "baselines = [\n",
    "    0, # full random\n",
    "    0, # no-repeats random\n",
    "    0  # only adjacent\n",
    "]\n",
    "legal = 0\n",
    "bar = tqdm(othello)\n",
    "for seq in bar:\n",
    "    ob = OthelloBoardState()\n",
    "    for i, move in enumerate(seq):\n",
    "        baselines[0] += 60\n",
    "        baselines[1] += 60 - i\n",
    "        baselines[2] += check_adj(ob)        \n",
    "        legal += len(ob.get_valid_moves())\n",
    "        ob.update([move])\n",
    "    bar.set_description(desc=f\"{legal}/{baselines[0]}, {legal/baselines[0]:.4f}\")\n",
    "\n",
    "for b in baselines:\n",
    "    print(legal/b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "othello",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
