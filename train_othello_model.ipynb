{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make deterministic\n",
    "from mingpt.utils import set_seed\n",
    "set_seed(44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from data.othello import Othello, OthelloBoardState, permit_reverse\n",
    "from mingpt.dataset import CharDataset\n",
    "from mingpt.utils import sample\n",
    "from mingpt.model import GPT, GPTConfig\n",
    "from mingpt.trainer import Trainer, TrainerConfig"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_games=-1 means use as many simulated games as possible (from \"data/othello_synthetic/\")\n",
    "othello = Othello(n_games=-1, data_root=\"othello_synthetic\")\n",
    "train_dataset = CharDataset(othello)\n",
    "# original OthelloGPT params: n_layer=8, n_head=8, n_embd=512\n",
    "mconf = GPTConfig(train_dataset.vocab_size, train_dataset.block_size, n_layer=8, n_head=8, n_embd=512)\n",
    "model = GPT(mconf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mem Used: 4.171 GB: 100%|██████████| 50/50 [00:17<00:00,  2.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5000000 from 50 files\n",
      "Deduplicating finished with 5000000 games left\n",
      "Using 4000000 for training, 1000000 for validation\n"
     ]
    }
   ],
   "source": [
    "othello = Othello(n_games=-1, data_root=\"othello_synthetic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created has 100 sequences, 61 unique words.\n"
     ]
    }
   ],
   "source": [
    "# for fine-tuning on fewer games\n",
    "n = 100\n",
    "train_dataset = CharDataset(othello[:n])\n",
    "# original OthelloGPT params: n_layer=8, n_head=8, n_embd=512\n",
    "mconf = GPTConfig(train_dataset.vocab_size, train_dataset.block_size, n_layer=8, n_head=8, n_embd=512)\n",
    "model = GPT(mconf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mem Used: 4.449 GB: 100%|██████████| 50/50 [00:20<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5000000 from 50 files\n",
      "Using 4000000 for training, 1000000 for validation\n",
      "Dataset created has 4000000 sequences, 61 unique words.\n"
     ]
    }
   ],
   "source": [
    "# for player type training run\n",
    "othello = Othello(n_games=-1, data_root=\"othello_1player\", deduplicate=False)\n",
    "\n",
    "seq = [p[1] for p in othello]\n",
    "\n",
    "train_dataset = CharDataset(seq)\n",
    "# original OthelloGPT params: n_layer=8, n_head=8, n_embd=512\n",
    "mconf = GPTConfig(train_dataset.vocab_size, train_dataset.block_size, n_layer=8, n_head=8, n_embd=512)\n",
    "model = GPT(mconf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_res = model.load_state_dict(torch.load(f\"./ckpts/bias/TLbias80.ckpt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.cuda.current_device()\n",
    "    model = model.to(device)\n",
    "else:\n",
    "    print(\"NO GPU FOUND\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_20230720_185718\n"
     ]
    }
   ],
   "source": [
    "# setting up training\n",
    "max_epochs = 100\n",
    "experiment_name = \"playertype_\"\n",
    "t_start = time.strftime(\"_%Y%m%d_%H%M%S\")\n",
    "ckpt_path = f\"./ckpts/{experiment_name}_{t_start}.ckpt\"\n",
    "tconf = TrainerConfig(\n",
    "    max_epochs=max_epochs, \n",
    "    batch_size=512*4, # using 4 gpus\n",
    "    # learning_rate=1e-4,\n",
    "    # lr_decay=False,\n",
    "    learning_rate=5e-4,\n",
    "    lr_decay=True, \n",
    "    warmup_tokens=len(train_dataset)*train_dataset.block_size*5, \n",
    "    final_tokens=len(train_dataset)*train_dataset.block_size*max_epochs,\n",
    "    num_workers=0, \n",
    "    ckpt_path=ckpt_path, \n",
    "    saved_epochs=[10, 20, 40, 80],\n",
    ")\n",
    "trainer = Trainer(model, train_dataset, None, tconf)\n",
    "device = trainer.device\n",
    "print(t_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1954 [00:00<?, ?it/s]/net/scratch/jnbaldwin/miniconda3/envs/othello/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "epoch 1 iter 1953: train loss 1.27189. lr 1.000000e-04: 100%|██████████| 1954/1954 [11:03<00:00,  2.94it/s]\n",
      "epoch 2 iter 1953: train loss 1.05247. lr 2.000000e-04: 100%|██████████| 1954/1954 [10:51<00:00,  3.00it/s]\n",
      "epoch 3 iter 1953: train loss 0.93706. lr 3.000000e-04: 100%|██████████| 1954/1954 [10:50<00:00,  3.00it/s]\n",
      "epoch 4 iter 1953: train loss 0.90153. lr 4.000000e-04: 100%|██████████| 1954/1954 [10:50<00:00,  3.00it/s]\n",
      "epoch 5 iter 1953: train loss 0.86758. lr 5.000000e-04: 100%|██████████| 1954/1954 [10:51<00:00,  3.00it/s]\n",
      "epoch 6 iter 1953: train loss 0.80442. lr 4.998633e-04: 100%|██████████| 1954/1954 [10:51<00:00,  3.00it/s]\n",
      "epoch 7 iter 1953: train loss 0.77039. lr 4.994534e-04: 100%|██████████| 1954/1954 [10:53<00:00,  2.99it/s]\n",
      "epoch 8 iter 1953: train loss 0.76682. lr 4.987707e-04: 100%|██████████| 1954/1954 [10:51<00:00,  3.00it/s]\n",
      "epoch 9 iter 1953: train loss 0.76409. lr 4.978160e-04: 100%|██████████| 1954/1954 [10:51<00:00,  3.00it/s]\n",
      "epoch 10 iter 1953: train loss 0.77011. lr 4.965903e-04: 100%|██████████| 1954/1954 [10:51<00:00,  3.00it/s]\n",
      "epoch 11 iter 1953: train loss 0.75868. lr 4.950950e-04: 100%|██████████| 1954/1954 [10:51<00:00,  3.00it/s]\n",
      "epoch 12 iter 1953: train loss 0.74661. lr 4.933316e-04: 100%|██████████| 1954/1954 [10:51<00:00,  3.00it/s]\n",
      "epoch 13 iter 1953: train loss 0.76831. lr 4.913022e-04: 100%|██████████| 1954/1954 [10:51<00:00,  3.00it/s]\n",
      "epoch 14 iter 1953: train loss 0.72719. lr 4.890089e-04: 100%|██████████| 1954/1954 [10:52<00:00,  3.00it/s]\n",
      "epoch 15 iter 1953: train loss 0.73089. lr 4.864543e-04: 100%|██████████| 1954/1954 [10:52<00:00,  2.99it/s]\n",
      "epoch 16 iter 1953: train loss 0.73932. lr 4.836411e-04: 100%|██████████| 1954/1954 [10:54<00:00,  2.99it/s]\n",
      "epoch 17 iter 1953: train loss 0.73064. lr 4.805724e-04: 100%|██████████| 1954/1954 [10:51<00:00,  3.00it/s]\n",
      "epoch 18 iter 1953: train loss 0.73171. lr 4.772516e-04: 100%|██████████| 1954/1954 [10:52<00:00,  3.00it/s]\n",
      "epoch 19 iter 1953: train loss 0.72045. lr 4.736823e-04: 100%|██████████| 1954/1954 [10:51<00:00,  3.00it/s]\n",
      "epoch 20 iter 1953: train loss 0.72847. lr 4.698684e-04: 100%|██████████| 1954/1954 [10:51<00:00,  3.00it/s]\n",
      "epoch 21 iter 1953: train loss 0.73798. lr 4.658141e-04: 100%|██████████| 1954/1954 [10:52<00:00,  2.99it/s]\n",
      "epoch 22 iter 1953: train loss 0.71250. lr 4.615238e-04: 100%|██████████| 1954/1954 [10:52<00:00,  3.00it/s]\n",
      "epoch 23 iter 1953: train loss 0.71416. lr 4.570022e-04: 100%|██████████| 1954/1954 [10:54<00:00,  2.99it/s]\n",
      "epoch 24 iter 1953: train loss 0.72287. lr 4.522542e-04: 100%|██████████| 1954/1954 [10:52<00:00,  2.99it/s]\n",
      "epoch 25 iter 1953: train loss 0.71405. lr 4.472851e-04: 100%|██████████| 1954/1954 [10:51<00:00,  3.00it/s]\n",
      "epoch 26 iter 1953: train loss 0.70739. lr 4.421003e-04: 100%|██████████| 1954/1954 [10:51<00:00,  3.00it/s]\n",
      "epoch 27 iter 1953: train loss 0.72435. lr 4.367054e-04: 100%|██████████| 1954/1954 [10:52<00:00,  2.99it/s]\n",
      "epoch 28 iter 1953: train loss 0.73607. lr 4.311063e-04: 100%|██████████| 1954/1954 [10:51<00:00,  3.00it/s]\n",
      "epoch 29 iter 1953: train loss 0.73296. lr 4.253092e-04: 100%|██████████| 1954/1954 [10:52<00:00,  2.99it/s]\n",
      "epoch 30 iter 1953: train loss 0.74350. lr 4.193204e-04: 100%|██████████| 1954/1954 [10:52<00:00,  2.99it/s]\n",
      "epoch 31 iter 1953: train loss 0.72438. lr 4.131464e-04: 100%|██████████| 1954/1954 [10:54<00:00,  2.99it/s]\n",
      "epoch 32 iter 1953: train loss 0.70998. lr 4.067941e-04: 100%|██████████| 1954/1954 [10:52<00:00,  2.99it/s]\n",
      "epoch 33 iter 1953: train loss 0.71435. lr 4.002703e-04: 100%|██████████| 1954/1954 [10:50<00:00,  3.01it/s]\n",
      "epoch 34 iter 1953: train loss 0.71798. lr 3.935822e-04: 100%|██████████| 1954/1954 [10:55<00:00,  2.98it/s]\n",
      "epoch 35 iter 1953: train loss 0.71807. lr 3.867370e-04: 100%|██████████| 1954/1954 [10:53<00:00,  2.99it/s]\n",
      "epoch 36 iter 1953: train loss 0.71511. lr 3.797424e-04: 100%|██████████| 1954/1954 [10:52<00:00,  2.99it/s]\n",
      "epoch 37 iter 1953: train loss 0.71324. lr 3.726059e-04: 100%|██████████| 1954/1954 [10:52<00:00,  3.00it/s]\n",
      "epoch 38 iter 1953: train loss 0.72941. lr 3.653353e-04: 100%|██████████| 1954/1954 [10:53<00:00,  2.99it/s]\n",
      "epoch 39 iter 1953: train loss 0.70397. lr 3.579386e-04: 100%|██████████| 1954/1954 [10:53<00:00,  2.99it/s]\n",
      "epoch 40 iter 1953: train loss 0.72545. lr 3.504239e-04: 100%|██████████| 1954/1954 [10:52<00:00,  2.99it/s]\n",
      "epoch 41 iter 1953: train loss 0.71326. lr 3.427993e-04: 100%|██████████| 1954/1954 [10:52<00:00,  3.00it/s]\n",
      "epoch 42 iter 1262: train loss 0.70274. lr 3.378143e-04:  65%|██████▍   | 1263/1954 [07:02<03:47,  3.04it/s]"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_othello_model(ckpt):\n",
    "    # original OthelloGPT params: n_layer=8, n_head=8, n_embd=512\n",
    "    # vocab_size = 59, block_size = 61 for othello\n",
    "    mconf = GPTConfig(61, 59, n_layer=8, n_head=8, n_embd=512)\n",
    "    model = GPT(mconf)\n",
    "    load_res = model.load_state_dict(torch.load(f\"./ckpts/{ckpt}.ckpt\"))\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.cuda.current_device()\n",
    "        model = model.to(device)\n",
    "        return model, device\n",
    "    else:\n",
    "        print(\"NO GPU FOUND\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checks if model prediction is legal for each node in given game\n",
    "# expects dataset has already been loaded and model is on GPU\n",
    "def check_legal(model, device, train_dataset, game):\n",
    "    total_nodes = 0\n",
    "    success_nodes = 0\n",
    "\n",
    "    len_whole_game = len(game)\n",
    "    for len_partial_game in range(1, len_whole_game):\n",
    "        total_nodes += 1\n",
    "        context = game[:len_partial_game]\n",
    "        x = torch.tensor([train_dataset.stoi[s] for s in context], dtype=torch.long)[None, ...].to(device)\n",
    "        y = sample(model, x, 1, temperature=1.0)\n",
    "        # taking top-1 prediction\n",
    "        completion = [train_dataset.itos[int(i)] for i in y[0] if i != -1]\n",
    "        try:\n",
    "            OthelloBoardState().update(completion)\n",
    "        except Exception:\n",
    "            # print(completion)\n",
    "            pass\n",
    "        else:\n",
    "            success_nodes += 1\n",
    "    \n",
    "    return total_nodes, success_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default data root is othello_synthetic\n",
    "def validate_with_dataset(model, device, data_root=None, n_games=1000):\n",
    "    # find to load in first n games, because the first ~1 million othello_synthetic games are test set for unbiased model\n",
    "    val_games = Othello(data_root=data_root, n_games=n_games, test_split=1, deduplicate=False)\n",
    "    char = CharDataset(val_games.val)\n",
    "\n",
    "    total_nodes = 0\n",
    "    success_nodes = 0\n",
    "\n",
    "    def progress_report():\n",
    "        return f\"{success_nodes/total_nodes*100:.4f}% pass rate: {success_nodes}/{total_nodes} among all searched nodes\"\n",
    "    \n",
    "    bar = tqdm(val_games.val[:n_games])\n",
    "    for game in bar:\n",
    "        tn, sn = check_legal(model, device, char, game)\n",
    "        total_nodes += tn\n",
    "        success_nodes += sn\n",
    "        bar.set_description(progress_report())\n",
    "    print(progress_report())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_from_checkpoint(ckpt, data_root=None, n_games=1000):\n",
    "    model, device = load_othello_model(ckpt)\n",
    "    validate_with_dataset(model, device, data_root=data_root, n_games=n_games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mem Used: 4.062 GB:   0%|          | 0/50 [00:00<?, ?it/s]\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 100000 from 1 files\n",
      "Using 0 for training, 1000 for validation\n",
      "Dataset created has 1000 sequences, 61 unique words.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "99.9474% pass rate: 58909/58940 among all searched nodes: 100%|██████████| 1000/1000 [06:48<00:00,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.9474% pass rate: 58909/58940 among all searched nodes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "validate_from_checkpoint(\"bias/finetune_bias80_e5\", data_root=\"othello_synthetic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in [\"bias/TLcontrol\", \"bias/TLbias50\", \"bias/TLbias80\", \"bias/TLbias95\"]:\n",
    "    for dr in [\"synthetic\", \"TLbias50\", \"TLbias80\", \"TLbias95\"]:\n",
    "        print(f\"======== ckpt: {c} | data: {dr} =========\")\n",
    "        validate_from_checkpoint(c, data_root=f\"othello_{dr}\", n_games=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baselines for legal move accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eight directions\n",
    "eights = [[-1, 0], [-1, 1], [0, 1], [1, 1], [1, 0], [1, -1], [0, -1], [-1, -1]]\n",
    "# adds up empty spaces in current board state that have an adjacent occupied square\n",
    "def check_adj(ob):\n",
    "    total = 0\n",
    "    occupied = ob.get_occupied()\n",
    "    for i in range(64):\n",
    "        r, c = i // 8, i % 8\n",
    "        adj = False\n",
    "        if occupied[i]:\n",
    "            continue\n",
    "        for dir in eights:\n",
    "            test_r, test_c = r + dir[0], c + dir[1]\n",
    "            if test_r not in range(8) or test_c not in range(8):\n",
    "                continue\n",
    "            if occupied[test_r * 8 + test_c]:\n",
    "                adj = True\n",
    "                break\n",
    "        total += 1 if adj else 0\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "othello = Othello(data_root=\"othello_synthetic\", n_games=1000, test_split=0, deduplicate=False)\n",
    "baselines = [\n",
    "    0, # full random\n",
    "    0, # no-repeats random\n",
    "    0  # only adjacent\n",
    "]\n",
    "legal = 0\n",
    "bar = tqdm(othello)\n",
    "for seq in bar:\n",
    "    ob = OthelloBoardState()\n",
    "    for i, move in enumerate(seq):\n",
    "        baselines[0] += 60\n",
    "        baselines[1] += 60 - i\n",
    "        baselines[2] += check_adj(ob)        \n",
    "        legal += len(ob.get_valid_moves())\n",
    "        ob.update([move])\n",
    "    bar.set_description(desc=f\"{legal}/{baselines[0]}, {legal/baselines[0]:.4f}\")\n",
    "\n",
    "for b in baselines:\n",
    "    print(legal/b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "othello",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
