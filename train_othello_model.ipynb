{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make deterministic\n",
    "from mingpt.utils import set_seed\n",
    "set_seed(44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from data.othello import Othello, OthelloBoardState, permit_reverse\n",
    "from mingpt.dataset import CharDataset\n",
    "from mingpt.utils import sample\n",
    "from mingpt.model import GPT, GPTConfig\n",
    "from mingpt.trainer import Trainer, TrainerConfig"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_games=-1 means use as many simulated games as possible (from \"data/othello_synthetic/\")\n",
    "othello = Othello(n_games=-1, data_root=\"othello_synthetic\")\n",
    "train_dataset = CharDataset(othello)\n",
    "# original OthelloGPT params: n_layer=8, n_head=8, n_embd=512\n",
    "mconf = GPTConfig(train_dataset.vocab_size, train_dataset.block_size, n_layer=8, n_head=8, n_embd=512)\n",
    "model = GPT(mconf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mem Used: 14.0 GB: 100%|██████████| 50/50 [00:34<00:00,  1.47it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5000000 from 50 files\n",
      "Deduplicating finished with 5000000 games left\n",
      "Using 4000000 for training, 1000000 for validation\n"
     ]
    }
   ],
   "source": [
    "othello = Othello(n_games=-1, data_root=\"othello_synthetic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created has 1000 sequences, 61 unique words.\n"
     ]
    }
   ],
   "source": [
    "n = 1000\n",
    "train_dataset = CharDataset(othello[:n])\n",
    "# original OthelloGPT params: n_layer=8, n_head=8, n_embd=512\n",
    "mconf = GPTConfig(train_dataset.vocab_size, train_dataset.block_size, n_layer=8, n_head=8, n_embd=512)\n",
    "model = GPT(mconf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_res = model.load_state_dict(torch.load(f\"./ckpts/bias/TLbias80.ckpt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.cuda.current_device()\n",
    "    model = model.to(device)\n",
    "else:\n",
    "    print(\"NO GPU FOUND\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_20230712_202339\n"
     ]
    }
   ],
   "source": [
    "# setting up training\n",
    "max_epochs = 50\n",
    "experiment_name = \"ft_bias50_1k\"\n",
    "t_start = time.strftime(\"_%Y%m%d_%H%M%S\")\n",
    "ckpt_path = f\"./ckpts/{experiment_name}_{t_start}.ckpt\"\n",
    "tconf = TrainerConfig(\n",
    "    max_epochs=max_epochs, \n",
    "    batch_size=512*4, # using 4 gpus\n",
    "    learning_rate=1e-4,\n",
    "    lr_decay=False,\n",
    "    # learning_rate=5e-4,\n",
    "    # lr_decay=True, \n",
    "    warmup_tokens=len(train_dataset)*train_dataset.block_size*5, \n",
    "    final_tokens=len(train_dataset)*train_dataset.block_size*max_epochs,\n",
    "    num_workers=0, \n",
    "    ckpt_path=ckpt_path, \n",
    "    saved_epochs=[1, 5, 10, 20, 50],\n",
    ")\n",
    "trainer = Trainer(model, train_dataset, None, tconf)\n",
    "device = trainer.device\n",
    "print(t_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 0: train loss 1.59746. lr 1.000000e-04: 100%|██████████| 1/1 [00:00<00:00,  4.71it/s]\n",
      "epoch 2 iter 0: train loss 1.59969. lr 1.000000e-04: 100%|██████████| 1/1 [00:00<00:00,  4.53it/s]\n",
      "epoch 3 iter 0: train loss 1.58405. lr 1.000000e-04: 100%|██████████| 1/1 [00:00<00:00,  4.73it/s]\n",
      "epoch 4 iter 0: train loss 1.56763. lr 1.000000e-04: 100%|██████████| 1/1 [00:00<00:00,  4.66it/s]\n",
      "epoch 5 iter 0: train loss 1.55075. lr 1.000000e-04: 100%|██████████| 1/1 [00:00<00:00,  4.82it/s]\n",
      "epoch 6 iter 0: train loss 1.53321. lr 1.000000e-04: 100%|██████████| 1/1 [00:00<00:00,  4.84it/s]\n",
      "epoch 7 iter 0: train loss 1.51654. lr 1.000000e-04: 100%|██████████| 1/1 [00:00<00:00,  4.81it/s]\n",
      "epoch 8 iter 0: train loss 1.50591. lr 1.000000e-04: 100%|██████████| 1/1 [00:00<00:00,  5.06it/s]\n",
      "epoch 9 iter 0: train loss 1.48823. lr 1.000000e-04: 100%|██████████| 1/1 [00:00<00:00,  4.81it/s]\n",
      "epoch 10 iter 0: train loss 1.47151. lr 1.000000e-04: 100%|██████████| 1/1 [00:00<00:00,  4.43it/s]\n",
      "epoch 11 iter 0: train loss 1.45881. lr 1.000000e-04: 100%|██████████| 1/1 [00:00<00:00,  4.59it/s]\n",
      "epoch 12 iter 0: train loss 1.44438. lr 1.000000e-04: 100%|██████████| 1/1 [00:00<00:00,  4.62it/s]\n",
      "epoch 13 iter 0: train loss 1.42368. lr 1.000000e-04: 100%|██████████| 1/1 [00:00<00:00,  4.36it/s]\n",
      "epoch 14 iter 0: train loss 1.40880. lr 1.000000e-04: 100%|██████████| 1/1 [00:00<00:00,  4.28it/s]\n",
      "epoch 15 iter 0: train loss 1.39164. lr 1.000000e-04: 100%|██████████| 1/1 [00:00<00:00,  4.22it/s]\n",
      "epoch 16 iter 0: train loss 1.37650. lr 1.000000e-04: 100%|██████████| 1/1 [00:00<00:00,  4.54it/s]\n",
      "epoch 17 iter 0: train loss 1.35824. lr 1.000000e-04: 100%|██████████| 1/1 [00:00<00:00,  4.52it/s]\n",
      "epoch 18 iter 0: train loss 1.34114. lr 1.000000e-04: 100%|██████████| 1/1 [00:00<00:00,  4.37it/s]\n",
      "epoch 19 iter 0: train loss 1.32213. lr 1.000000e-04: 100%|██████████| 1/1 [00:00<00:00,  4.02it/s]\n",
      "epoch 20 iter 0: train loss 1.30540. lr 1.000000e-04: 100%|██████████| 1/1 [00:00<00:00,  4.55it/s]\n",
      "epoch 21 iter 0: train loss 1.29610. lr 1.000000e-04: 100%|██████████| 1/1 [00:00<00:00,  4.67it/s]\n",
      "epoch 22 iter 0: train loss 1.27870. lr 1.000000e-04: 100%|██████████| 1/1 [00:00<00:00,  4.65it/s]\n",
      "epoch 23 iter 0: train loss 1.25726. lr 1.000000e-04: 100%|██████████| 1/1 [00:00<00:00,  4.81it/s]\n",
      "epoch 24 iter 0: train loss 1.23702. lr 1.000000e-04: 100%|██████████| 1/1 [00:00<00:00,  4.69it/s]\n",
      "epoch 25 iter 0: train loss 1.22933. lr 1.000000e-04: 100%|██████████| 1/1 [00:00<00:00,  4.79it/s]\n",
      "epoch 26 iter 0: train loss 1.20657. lr 1.000000e-04: 100%|██████████| 1/1 [00:00<00:00,  4.79it/s]\n",
      "epoch 27 iter 0: train loss 1.19011. lr 1.000000e-04: 100%|██████████| 1/1 [00:00<00:00,  4.52it/s]\n",
      "epoch 28 iter 0: train loss 1.17643. lr 1.000000e-04: 100%|██████████| 1/1 [00:00<00:00,  4.71it/s]\n",
      "epoch 29 iter 0: train loss 1.15795. lr 1.000000e-04: 100%|██████████| 1/1 [00:00<00:00,  4.56it/s]\n",
      "epoch 30 iter 0: train loss 1.14217. lr 1.000000e-04: 100%|██████████| 1/1 [00:00<00:00,  4.78it/s]\n",
      "epoch 31 iter 0: train loss 1.12262. lr 1.000000e-04: 100%|██████████| 1/1 [00:00<00:00,  4.85it/s]\n",
      "epoch 32 iter 0: train loss 1.10908. lr 1.000000e-04: 100%|██████████| 1/1 [00:00<00:00,  4.68it/s]\n",
      "epoch 33 iter 0: train loss 1.09167. lr 1.000000e-04: 100%|██████████| 1/1 [00:00<00:00,  4.44it/s]\n",
      "epoch 34 iter 0: train loss 1.07324. lr 1.000000e-04: 100%|██████████| 1/1 [00:00<00:00,  4.19it/s]\n",
      "epoch 35 iter 0: train loss 1.05806. lr 1.000000e-04: 100%|██████████| 1/1 [00:00<00:00,  4.70it/s]\n",
      "epoch 36 iter 0: train loss 1.04314. lr 1.000000e-04: 100%|██████████| 1/1 [00:00<00:00,  4.49it/s]\n",
      "epoch 37 iter 0: train loss 1.02564. lr 1.000000e-04: 100%|██████████| 1/1 [00:00<00:00,  4.76it/s]\n",
      "epoch 38 iter 0: train loss 1.00381. lr 1.000000e-04: 100%|██████████| 1/1 [00:00<00:00,  4.44it/s]\n",
      "epoch 39 iter 0: train loss 0.99308. lr 1.000000e-04: 100%|██████████| 1/1 [00:00<00:00,  4.57it/s]\n",
      "epoch 40 iter 0: train loss 0.98146. lr 1.000000e-04: 100%|██████████| 1/1 [00:00<00:00,  4.70it/s]\n",
      "epoch 41 iter 0: train loss 0.96022. lr 1.000000e-04: 100%|██████████| 1/1 [00:00<00:00,  4.70it/s]\n",
      "epoch 42 iter 0: train loss 0.94500. lr 1.000000e-04: 100%|██████████| 1/1 [00:00<00:00,  4.80it/s]\n",
      "epoch 43 iter 0: train loss 0.93079. lr 1.000000e-04: 100%|██████████| 1/1 [00:00<00:00,  4.68it/s]\n",
      "epoch 44 iter 0: train loss 0.91641. lr 1.000000e-04: 100%|██████████| 1/1 [00:00<00:00,  4.90it/s]\n",
      "epoch 45 iter 0: train loss 0.90385. lr 1.000000e-04: 100%|██████████| 1/1 [00:00<00:00,  4.77it/s]\n",
      "epoch 46 iter 0: train loss 0.88850. lr 1.000000e-04: 100%|██████████| 1/1 [00:00<00:00,  4.88it/s]\n",
      "epoch 47 iter 0: train loss 0.87211. lr 1.000000e-04: 100%|██████████| 1/1 [00:00<00:00,  4.86it/s]\n",
      "epoch 48 iter 0: train loss 0.85848. lr 1.000000e-04: 100%|██████████| 1/1 [00:00<00:00,  4.81it/s]\n",
      "epoch 49 iter 0: train loss 0.84078. lr 1.000000e-04: 100%|██████████| 1/1 [00:00<00:00,  4.47it/s]\n",
      "epoch 50 iter 0: train loss 0.82829. lr 1.000000e-04: 100%|██████████| 1/1 [00:00<00:00,  4.05it/s]\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_othello_model(ckpt):\n",
    "    # original OthelloGPT params: n_layer=8, n_head=8, n_embd=512\n",
    "    # vocab_size = 59, block_size = 61 for othello\n",
    "    mconf = GPTConfig(61, 59, n_layer=8, n_head=8, n_embd=512)\n",
    "    model = GPT(mconf)\n",
    "    load_res = model.load_state_dict(torch.load(f\"./ckpts/{ckpt}.ckpt\"))\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.cuda.current_device()\n",
    "        model = model.to(device)\n",
    "        return model, device\n",
    "    else:\n",
    "        print(\"NO GPU FOUND\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checks if model prediction is legal for each node in given game\n",
    "# expects dataset has already been loaded and model is on GPU\n",
    "def check_legal(model, device, train_dataset, game):\n",
    "    total_nodes = 0\n",
    "    success_nodes = 0\n",
    "\n",
    "    len_whole_game = len(game)\n",
    "    for len_partial_game in range(1, len_whole_game):\n",
    "        total_nodes += 1\n",
    "        context = game[:len_partial_game]\n",
    "        x = torch.tensor([train_dataset.stoi[s] for s in context], dtype=torch.long)[None, ...].to(device)\n",
    "        y = sample(model, x, 1, temperature=1.0)\n",
    "        # taking top-1 prediction\n",
    "        completion = [train_dataset.itos[int(i)] for i in y[0] if i != -1]\n",
    "        try:\n",
    "            OthelloBoardState().update(completion)\n",
    "        except Exception:\n",
    "            # print(completion)\n",
    "            pass\n",
    "        else:\n",
    "            success_nodes += 1\n",
    "    \n",
    "    return total_nodes, success_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default data root is othello_synthetic\n",
    "def validate_with_dataset(model, device, data_root=None, n_games=1000):\n",
    "    # find to load in first n games, because the first ~1 million othello_synthetic games are test set for unbiased model\n",
    "    val_games = Othello(data_root=data_root, n_games=n_games, test_split=1, deduplicate=False)\n",
    "    char = CharDataset(val_games.val)\n",
    "\n",
    "    total_nodes = 0\n",
    "    success_nodes = 0\n",
    "\n",
    "    def progress_report():\n",
    "        return f\"{success_nodes/total_nodes*100:.4f}% pass rate: {success_nodes}/{total_nodes} among all searched nodes\"\n",
    "    \n",
    "    bar = tqdm(val_games.val[:n_games])\n",
    "    for game in bar:\n",
    "        tn, sn = check_legal(model, device, char, game)\n",
    "        total_nodes += tn\n",
    "        success_nodes += sn\n",
    "        bar.set_description(progress_report())\n",
    "    print(progress_report())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_from_checkpoint(ckpt, data_root=None, n_games=1000):\n",
    "    model, device = load_othello_model(ckpt)\n",
    "    validate_with_dataset(model, device, data_root=data_root, n_games=n_games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mem Used: 4.062 GB:   0%|          | 0/50 [00:00<?, ?it/s]\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 100000 from 1 files\n",
      "Using 0 for training, 1000 for validation\n",
      "Dataset created has 1000 sequences, 61 unique words.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "99.9474% pass rate: 58909/58940 among all searched nodes: 100%|██████████| 1000/1000 [06:48<00:00,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.9474% pass rate: 58909/58940 among all searched nodes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "validate_from_checkpoint(\"bias/finetune_bias80_e5\", data_root=\"othello_synthetic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in [\"bias/TLcontrol\", \"bias/TLbias50\", \"bias/TLbias80\", \"bias/TLbias95\"]:\n",
    "    for dr in [\"synthetic\", \"TLbias50\", \"TLbias80\", \"TLbias95\"]:\n",
    "        print(f\"======== ckpt: {c} | data: {dr} =========\")\n",
    "        validate_from_checkpoint(c, data_root=f\"othello_{dr}\", n_games=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baselines for legal move accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eight directions\n",
    "eights = [[-1, 0], [-1, 1], [0, 1], [1, 1], [1, 0], [1, -1], [0, -1], [-1, -1]]\n",
    "# adds up empty spaces in current board state that have an adjacent occupied square\n",
    "def check_adj(ob):\n",
    "    total = 0\n",
    "    occupied = ob.get_occupied()\n",
    "    for i in range(64):\n",
    "        r, c = i // 8, i % 8\n",
    "        adj = False\n",
    "        if occupied[i]:\n",
    "            continue\n",
    "        for dir in eights:\n",
    "            test_r, test_c = r + dir[0], c + dir[1]\n",
    "            if test_r not in range(8) or test_c not in range(8):\n",
    "                continue\n",
    "            if occupied[test_r * 8 + test_c]:\n",
    "                adj = True\n",
    "                break\n",
    "        total += 1 if adj else 0\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "othello = Othello(data_root=\"othello_synthetic\", n_games=1000, test_split=0, deduplicate=False)\n",
    "baselines = [\n",
    "    0, # full random\n",
    "    0, # no-repeats random\n",
    "    0  # only adjacent\n",
    "]\n",
    "legal = 0\n",
    "bar = tqdm(othello)\n",
    "for seq in bar:\n",
    "    ob = OthelloBoardState()\n",
    "    for i, move in enumerate(seq):\n",
    "        baselines[0] += 60\n",
    "        baselines[1] += 60 - i\n",
    "        baselines[2] += check_adj(ob)        \n",
    "        legal += len(ob.get_valid_moves())\n",
    "        ob.update([move])\n",
    "    bar.set_description(desc=f\"{legal}/{baselines[0]}, {legal/baselines[0]:.4f}\")\n",
    "\n",
    "for b in baselines:\n",
    "    print(legal/b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "othello",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
